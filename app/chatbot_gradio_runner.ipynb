{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI for Audio Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restart Kernel (If needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "Most of the complexity for the chatbot is in [customizable_chatbot.py](./customizable_chatbot.py) that uses [audio.py](./audio.py) internally for the audio capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from genai_voice.bots.chatbot import ChatBot\n",
    "from genai_voice.config.defaults import Config\n",
    "from genai_voice.logger.log_utils import log, LogLevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(f'Configuration: {Config()}', log_level=LogLevels.ON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Current Working Directory  \n",
    "\n",
    "We want to simulate running this notebook from the project root just as it would work when using `Poetry` scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_wrk_dir = os.getcwd()\n",
    "log(f'Before directory change: {curr_wrk_dir}')\n",
    "if curr_wrk_dir.endswith('app'):\n",
    "    log(f'Changing directory to root')\n",
    "    os.chdir('..')\n",
    "    curr_wrk_dir = os.getcwd()\n",
    "log(f'Before directory change: {curr_wrk_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data for LLM Context  \n",
    "\n",
    "`Poetry` scripts allow us to install our code as a package and run functions executables. \n",
    "\n",
    "We will use the `ExtractWebPagesAndSaveData` script, that is defined in `pyproject.toml` to scrape, extract and generate the file that the LLM will use as context data.\n",
    "\n",
    "`SAMPLE_URLS` have been defined under provided under `genai_voice.data_utils.urls.py`. Feel free to modify the links in that file to customize the source of data. \n",
    "\n",
    "> **DISCLAIMER:** Be responsible when scraping data that is not yours, complying with the EULA of the sites and conducting it in a legal fashion. Also remember that most sites will throttle scrapes, so do this with caution.  \n",
    "\n",
    "> **NOTE:** This is an optional step. It just shows you have you can get custom data for your LLM context. We have provided the data for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run ExtractWebPagesAndSaveData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Interface\n",
    "This launches the UI, you will probably need to allow the browser to use the microphone to enable the audio functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run Chatbot app\"\"\"\n",
    "chatbot = ChatBot(enable_speakers=True, threaded=True)\n",
    "history = []\n",
    "\n",
    "def get_response(audio):\n",
    "    \"\"\"Get Audio Response From Chatbot\"\"\"\n",
    "    if not audio:\n",
    "        raise ValueError(\"No audio file provided.\")\n",
    "    prompt = chatbot.get_prompt_from_gradio_audio(audio)\n",
    "    log(f\"Transcribed prompt: {prompt}\", log_level=LogLevels.ON)\n",
    "    response = chatbot.respond(prompt, history)\n",
    "    log(f\"Chatbot response: {response}\", log_level=LogLevels.ON)\n",
    "    history.append([prompt, response])\n",
    "    return response\n",
    "\n",
    "demo = gr.Interface(\n",
    "        get_response,\n",
    "        gr.Audio(sources=\"microphone\"),\n",
    "        None,\n",
    "        title=\"Wanderwise Travel Assistant\"\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (agentic-ai)",
   "language": "python",
   "name": "agentic-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
